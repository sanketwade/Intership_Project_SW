{"cells":[{"cell_type":"code","source":["%run data_injection_notebook_sw\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[3,4,5],"state":"finished","livy_statement_state":"available","session_id":"57937d1c-a62c-4e9b-a54c-43fad53bcc5a","normalized_state":"finished","queued_time":"2025-04-05T03:00:50.4742717Z","session_start_time":null,"execution_start_time":"2025-04-05T03:00:50.8816926Z","execution_finish_time":"2025-04-05T03:01:06.7601215Z","parent_msg_id":"8103eeca-1564-4767-ac54-74586e9a515e"},"text/plain":"StatementMeta(, 57937d1c-a62c-4e9b-a54c-43fad53bcc5a, 5, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["HR data successfully loaded into the Staging Layer: 'hr_data_staging.csv'\n"]}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"772a8237-aa78-4bc9-82d8-6e779fd2295d"},{"cell_type":"code","source":["# Data Informanation \n","\n","# ------------------------------------------------------------\n","# Schema and Row Count of HR Staging Data\n","# ------------------------------------------------------------\n","# This block helps inspect the structure (column names, types, nullability)\n","# and size (total number of records) of the staging DataFrame.\n","# ------------------------------------------------------------\n","\n","hr_staging_df.printSchema()  # Print the schema of the HR Staging DataFrame\n","print(\"Number of rows \",hr_staging_df.count())"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"cancelled","livy_statement_state":null,"session_id":"efa315f7-5ecf-495f-94a9-2707c12629bb","normalized_state":"cancelled","queued_time":"2025-04-05T01:13:38.2686485Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2025-04-05T01:13:43.4207738Z","parent_msg_id":"f932a79b-c969-4be3-9afe-08b0771eed3f"},"text/plain":"StatementMeta(, efa315f7-5ecf-495f-94a9-2707c12629bb, -1, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c1bfdef9-5cff-4e6d-baf9-74b11e66ae3b"},{"cell_type":"code","source":["# ------------------------------------------------------------\n","# Null Value Check in HR Staging Data\n","# ------------------------------------------------------------\n","# This block calculates the number of null values in each column\n","# of the staging DataFrame (`hr_staging_df`).\n","# Useful for identifying data quality issues before transformations.\n","# ------------------------------------------------------------\n","\n","from pyspark.sql.functions import col, sum\n","display(hr_staging_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in hr_staging_df.columns])) "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"cancelled","livy_statement_state":null,"session_id":"efa315f7-5ecf-495f-94a9-2707c12629bb","normalized_state":"cancelled","queued_time":"2025-04-05T01:13:38.3330669Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":"2025-04-05T01:13:43.4210627Z","parent_msg_id":"dc0efe0c-87d0-40aa-a7c2-c48e78ca23e9"},"text/plain":"StatementMeta(, efa315f7-5ecf-495f-94a9-2707c12629bb, -1, Cancelled, , Cancelled)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"b4e949ac-fbe0-4b22-bd46-cb5d8e15906c"},{"cell_type":"code","source":["# ------------------------------------------------------------\n","# HR Data Pipeline: Staging to Bronze Layer\n","# ------------------------------------------------------------\n","# This script reads raw HR data from the staging layer (CSV),\n","# processes it, and writes it to the bronze layer in Parquet format.\n","# ------------------------------------------------------------\n","\n","# Define file paths\n","staging_file_path = injection_lh_fpath + \"//\" + \"hr_data_staging.csv\"  # Staging layer file (CSV format)\n","bronze_file_path = bronz_lh_fpath + \"//\" + \"hr_data_bronze.parquet\"    # Bronze layer file (Parquet format)\n","\n","# Load the raw HR data from the Staging Layer (CSV)\n","hr_staging_df = (\n","    spark.read\n","    .option(\"header\", \"true\")             # First row contains headers\n","    .option(\"inferSchema\", \"true\")        # Automatically infer column data types\n","    .csv(staging_file_path)\n",")\n","\n","# Write the raw data into the Bronze Layer as a Parquet file\n","hr_staging_df.write.mode(\"overwrite\").parquet(bronze_file_path)\n","\n","# Optional: Load and verify the data from the Bronze Layer\n","bronze_df = spark.read.parquet(bronze_file_path)\n","\n","# Uncomment below to display sample records\n","# bronze_df.show(5)\n","# display(bronze_df)  # For notebooks\n","\n","# Confirmation message\n","print(\"âœ… HR data successfully moved to the Bronze Layer: 'hr_data_bronze.parquet'\")\n","\n","\n","\n","\n","# Define file paths\n","staging_file_path = injection_lh_fpath+\"//\"+\"hr_data_staging.csv\"  # Staging layer file (CSV)\n","bronze_file_path = bronz_lh_fpath+\"//\"+\"hr_data_bronze.parquet\"  # Bronze layer file (Parquet)\n","\n","# Load the raw HR data from Staging Layer (CSV)\n","hr_staging_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\",\"true\").csv(staging_file_path)\n","\n","# Write data into the Bronze Layer as Parquet\n","hr_staging_df.write.mode(\"overwrite\").parquet(bronze_file_path)\n","\n","# Show a few rows to verify\n","bronze_df = spark.read.parquet(bronze_file_path)\n","\n","# Uncomment below to display sample records\n","# bronze_df.show(5 )\n","# display(bronze_df)\n","\n","print(\"HR data successfully moved to the Bronze Layer: 'hr_data_bronze.parquet'\")\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":[],"state":"session_starting","livy_statement_state":null,"session_id":null,"normalized_state":"session_starting","queued_time":"2025-04-05T11:43:34.7142419Z","session_start_time":"2025-04-05T11:43:34.7152327Z","execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"88cb2c6b-2650-4ec0-8b7f-a8eb5572b8bb"},"text/plain":"StatementMeta(, , -1, SessionStarting, , SessionStarting)"},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"a2ebdb30-6ad3-46a4-92f2-80fe9452fbae"},{"cell_type":"code","source":["# hr_staging.write.mode(\"overwrite\").parquet(bronze_hr_data+'//'+'hr_data_bronze.parquet')\n","# print(\"Data successfully imported from Staging to Bronze Lakehouse in Parquet format.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":-1,"statement_ids":null,"state":"waiting","livy_statement_state":null,"session_id":null,"normalized_state":"waiting","queued_time":"2025-04-05T11:43:34.7190549Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"c05ce123-8aa6-43c5-8814-ad91b72e636b"},"text/plain":"StatementMeta(, , -1, Waiting, , Waiting)"},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e724e4de-c477-4680-9420-107c0aa262e3"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4281cb07-18f6-4309-8bcd-d022bb5e5fcf"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"421532b8-1425-408c-9ce6-1dda514f771e"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"4a3e96a5-8bbc-4d5b-91b8-6b376e7e5426"},{"id":"25bfd115-11a3-4374-9d4b-b13d828de952"},{"id":"e9f5a04e-2be9-4bcf-9614-a437a5ed5a6b"},{"id":"a2d678d1-157f-48cd-8c8e-4b982538d11d"},{"id":"d7d2675d-f8ad-4ccd-8539-55777c7df9a8"},{"id":"21b52038-c172-4add-abfa-b673bbfc01f7"}],"default_lakehouse":"4a3e96a5-8bbc-4d5b-91b8-6b376e7e5426","default_lakehouse_name":"gold_lakehouse_sw","default_lakehouse_workspace_id":"cc7fc8ef-05a5-4260-9f03-ba315c3d1a79"}}},"nbformat":4,"nbformat_minor":5}